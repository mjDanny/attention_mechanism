{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка необходимых библиотек\n",
        "%pip install tensorflow scikit-learn numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0qQaplFyUdv"
      },
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "import tensorflow as tf  # Библиотека для работы с нейронными сетями\n",
        "from tensorflow.keras.layers import Layer, LSTM, Embedding, Dense  # Импорт слоев для построения модели\n",
        "import numpy as np  # Библиотека для работы с массивами и математическими операциями\n",
        "import re  # Модуль для работы с регулярными выражениями\n",
        "from sklearn.model_selection import train_test_split  # Функция для разделения данных на обучающую и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xnm81nCyFe-",
        "outputId": "dcacda42-117c-4ccd-9e63-aa2002a0ea99"
      },
      "outputs": [],
      "source": [
        "# Скачивание файла с данными (замените ссылку на свою\n",
        "!wget https://storage.yandexcloud.net/academy.ai/LLM/dialogs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cwik5HCyGP9"
      },
      "outputs": [],
      "source": [
        "# Класс для реализации механизма внимания (Attention Mechanism)\n",
        "class AttentionMechanism(Layer):\n",
        "    def __init__(self, method, units):\n",
        "        super(AttentionMechanism, self).__init__()\n",
        "        self.method = method  # Метод внимания (например, 'bahdanau', 'luong_gen', 'luong_concat')\n",
        "        self.units = units  # Количество единиц (нейронов) в слоях внимания\n",
        "\n",
        "        # Инициализация слоев в зависимости от выбранного метода\n",
        "        if self.method == 'bahdanau':\n",
        "            # Слои для метода Bahdanau (аддитивное внимание)\n",
        "            self.W1 = Dense(units)  # Полносвязный слой для обработки запроса\n",
        "            self.W2 = Dense(units)  # Полносвязный слой для обработки значений\n",
        "            self.V = Dense(1)  # Полносвязный слой для вычисления score (оценки)\n",
        "        elif self.method == 'luong_gen':\n",
        "            # Слой для метода Luong (обобщенное внимание)\n",
        "            self.W = Dense(units)  # Полносвязный слой для обработки значений\n",
        "        elif self.method == 'luong_concat':\n",
        "            # Слои для метода Luong (конкатенационное внимание)\n",
        "            self.W = Dense(units)  # Полносвязный слой для обработки конкатенации\n",
        "            self.V = Dense(1)  # Полносвязный слой для вычисления score (оценки)\n",
        "\n",
        "    # Метод для вычисления контекстного вектора и весов внимания\n",
        "    def call(self, query, values):\n",
        "        if self.method == 'bahdanau':\n",
        "            # Метод Bahdanau: вычисление score с использованием tanh и аддитивной функции\n",
        "            query_with_time_axis = tf.expand_dims(query, 1)  # Добавление оси времени к запросу\n",
        "            score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))  # Вычисление score\n",
        "        elif self.method == 'luong_gen':\n",
        "            # Метод Luong (обобщенное внимание): вычисление score через матричное умножение\n",
        "            score = tf.matmul(values, tf.expand_dims(query, 2))  # Вычисление score\n",
        "        elif self.method == 'luong_concat':\n",
        "            # Метод Luong (конкатенационное внимание): вычисление score через конкатенацию и tanh\n",
        "            query_with_time_axis = tf.expand_dims(query, 1)  # Добавление оси времени к запросу\n",
        "            score = self.V(tf.nn.tanh(self.W(tf.concat([query_with_time_axis, values], axis=-1))))  # Вычисление score\n",
        "\n",
        "        # Вычисление весов внимания с помощью функции softmax\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        # Вычисление контекстного вектора как взвешенной суммы значений\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)  # Суммирование по оси времени\n",
        "\n",
        "        return context_vector, attention_weights  # Возврат контекстного вектора и весов внимания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0DgAIYFyKAO"
      },
      "outputs": [],
      "source": [
        "# Класс для реализации текстового энкодера (Text Encoder)\n",
        "class TextEncoder(Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.batch_sz = batch_sz  # Размер батча (количество примеров, обрабатываемых за один раз)\n",
        "        self.enc_units = enc_units  # Количество единиц (нейронов) в LSTM слое\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim)  # Слой для векторного представления слов (Embedding)\n",
        "        self.lstm = LSTM(self.enc_units, return_sequences=True, return_state=True)  # LSTM слой для обработки последовательностей\n",
        "\n",
        "    # Метод для обработки входных данных\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)  # Преобразование входных индексов слов в векторные представления\n",
        "        output, state_h, state_c = self.lstm(x)  # Обработка последовательности с помощью LSTM\n",
        "        return output, state_h, state_c  # Возврат выходных данных, скрытого состояния и состояния ячейки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAmUuLsTyK7n"
      },
      "outputs": [],
      "source": [
        "# Класс для реализации текстового декодера (Text Decoder)\n",
        "class TextDecoder(Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_method='bahdanau'):\n",
        "        super(TextDecoder, self).__init__()\n",
        "        self.batch_sz = batch_sz  # Размер батча (количество примеров, обрабатываемых за один раз)\n",
        "        self.dec_units = dec_units  # Количество единиц (нейронов) в LSTM слое\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim)  # Слой для векторного представления слов (Embedding)\n",
        "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True)  # LSTM слой для обработки последовательностей\n",
        "        self.fc = Dense(vocab_size)  # Полносвязный слой для предсказания следующего слова\n",
        "        self.attention = AttentionMechanism(method=attention_method, units=self.dec_units)  # Механизм внимания\n",
        "\n",
        "    # Метод для обработки входных данных\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # Вычисление контекстного вектора и весов внимания\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        # Преобразование входных индексов слов в векторные представления\n",
        "        x = self.embedding(x)\n",
        "        # Конкатенация контекстного вектора и векторного представления слова\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        # Обработка последовательности с помощью LSTM\n",
        "        output, state_h, state_c = self.lstm(x)\n",
        "        # Преобразование выходных данных LSTM в нужную форму\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        # Предсказание следующего слова с помощью полносвязного слоя\n",
        "        x = self.fc(output)\n",
        "        return x, state_h, state_c, attention_weights  # Возврат предсказания, скрытого состояния, состояния ячейки и весов внимания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BPaBliuyNH_"
      },
      "outputs": [],
      "source": [
        "# Функция для очистки предложения\n",
        "def clean_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()  # Приведение к нижнему регистру и удаление лишних пробелов\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)  # Добавление пробелов вокруг знаков препинания\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)  # Удаление лишних пробелов\n",
        "    sentence = re.sub(r\"[^a-zA-Zа-яА-Я?.!,¿]+\", \" \", sentence)  # Удаление всех символов, кроме букв и знаков препинания\n",
        "    sentence = sentence.strip()  # Удаление лишних пробелов в начале и конце предложения\n",
        "    sentence = '<start> ' + sentence + ' <end>'  # Добавление специальных токенов начала и конца предложения\n",
        "    return sentence\n",
        "\n",
        "# Функция для загрузки диалогов из файла\n",
        "def load_dialogs(path):\n",
        "    input_texts = []  # Список для хранения входных предложений\n",
        "    target_texts = []  # Список для хранения целевых предложений\n",
        "    with open(path, encoding='utf-8') as file:  # Открытие файла с диалогами\n",
        "        for line in file:\n",
        "            parts = line.strip().split(\"\\t\")  # Разделение строки на части по табуляции\n",
        "            if len(parts) == 2:  # Проверка, что строка содержит два предложения\n",
        "                input_texts.append(clean_sentence(parts[0]))  # Очистка и добавление входного предложения\n",
        "                target_texts.append(clean_sentence(parts[1]))  # Очистка и добавление целевого предложения\n",
        "    return input_texts, target_texts  # Возврат списков входных и целевых предложений\n",
        "\n",
        "# Функция для токенизации текстов\n",
        "def tokenize_texts(texts, vocab_size):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, filters='', oov_token='<unk>')  # Инициализация токенизатора\n",
        "    tokenizer.fit_on_texts(texts)  # Обучение токенизатора на текстах\n",
        "    tensor = tokenizer.texts_to_sequences(texts)  # Преобразование текстов в последовательности индексов\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  # Дополнение последовательностей до одинаковой длины\n",
        "    return tensor, tokenizer  # Возврат тензора и токенизатора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWkSYkWfyOYX"
      },
      "outputs": [],
      "source": [
        "# Путь к файлу с диалогами\n",
        "path = 'dialogs.txt'\n",
        "\n",
        "# Загрузка диалогов из файла\n",
        "input_texts, target_texts = load_dialogs(path)\n",
        "\n",
        "# Установка размера словаря\n",
        "vocab_size = 5000\n",
        "\n",
        "# Токенизация входных текстов\n",
        "input_tensor, inp_lang_tokenizer = tokenize_texts(input_texts, vocab_size)\n",
        "# Токенизация целевых текстов\n",
        "target_tensor, targ_lang_tokenizer = tokenize_texts(target_texts, vocab_size)\n",
        "\n",
        "# Разделение данных на обучающую и валидационную выборки\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
        "    input_tensor, target_tensor, test_size=0.2  # 20% данных используются для валидации\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F2gbotiyPko",
        "outputId": "901b9cd0-7652-44ae-9018-69afd1422a13"
      },
      "outputs": [],
      "source": [
        "# Установка параметров модели\n",
        "embedding_dim = 256  # Размерность векторного представления слов (Embedding)\n",
        "units = 512  # Количество нейронов в LSTM слое\n",
        "batch_size = 64  # Размер батча\n",
        "\n",
        "# Создание экземпляров энкодера и декодера\n",
        "encoder = TextEncoder(vocab_size, embedding_dim, units, batch_size)\n",
        "decoder = TextDecoder(vocab_size, embedding_dim, units, batch_size)\n",
        "\n",
        "# Инициализация оптимизатора и функции потерь\n",
        "optimizer = tf.keras.optimizers.Adam()  # Оптимизатор Adam\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')  # Функция потерь\n",
        "\n",
        "# Функция для вычисления потерь с учетом маскирования\n",
        "def calculate_loss(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))  # Создание маски для игнорирования нулевых значений (padding)\n",
        "    loss_ = loss_object(real, pred)  # Вычисление потерь\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)  # Приведение маски к типу данных потерь\n",
        "    loss_ *= mask  # Применение маски к потерям\n",
        "    return tf.reduce_mean(loss_)  # Возврат среднего значения потерь\n",
        "\n",
        "# Декорированная функция для выполнения одного шага обучения\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0  # Инициализация переменной для накопления потерь\n",
        "    with tf.GradientTape() as tape:  # Контекст для записи операций и вычисления градиентов\n",
        "        # Кодирование входных данных\n",
        "        enc_output, enc_hidden_h, enc_hidden_c = encoder(inp)\n",
        "        dec_hidden = enc_hidden_h  # Инициализация скрытого состояния декодера\n",
        "        # Начальный вход для декодера (токен <start>)\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * batch_size, 1)\n",
        "\n",
        "        # Цикл по временным шагам целевой последовательности\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # Декодирование и предсказание следующего слова\n",
        "            predictions, dec_hidden_h, dec_hidden_c, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            # Накопление потерь\n",
        "            loss += calculate_loss(targ[:, t], predictions)\n",
        "            # Обновление входного слова для следующего шага\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    # Вычисление средних потерь на батч\n",
        "    batch_loss = loss / int(targ.shape[1])\n",
        "    # Получение списка обучаемых переменных\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    # Вычисление градиентов\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    # Обновление весов модели\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss  # Возврат потерь на батч\n",
        "\n",
        "# Количество эпох обучения\n",
        "EPOCHS = 100\n",
        "\n",
        "# Цикл обучения\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0  # Инициализация переменной для накопления потерь за эпоху\n",
        "    enc_hidden = tf.zeros((batch_size, units))  # Инициализация скрытого состояния энкодера\n",
        "    # Цикл по батчам\n",
        "    for batch in range(len(input_tensor_train)//batch_size):\n",
        "        # Получение текущего батча\n",
        "        batch_input = input_tensor_train[batch*batch_size:(batch+1)*batch_size]\n",
        "        batch_target = target_tensor_train[batch*batch_size:(batch+1)*batch_size]\n",
        "        # Выполнение шага обучения и получение потерь\n",
        "        batch_loss = train_step(batch_input, batch_target, enc_hidden)\n",
        "        total_loss += batch_loss  # Накопление потерь\n",
        "    # Вывод средних потерь за эпоху\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(input_tensor_train)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "90Quri2byRWQ",
        "outputId": "86475f16-cccf-4bdc-f249-88093fa6e9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Перевод: i enjoy the kinds of instruments that i enjoy the kinds of instruments that i enjoy the kinds of instruments that i enjoy the \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-b10ca10af151>:38: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence.split(' '), rotation=90)\n",
            "<ipython-input-9-b10ca10af151>:39: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence.split(' '))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Функция для оценки (генерации перевода) предложения\n",
        "def evaluate_sentence(sentence):\n",
        "    attention_plot = np.zeros((max_len_targ, max_len_inp))  # Инициализация массива для хранения весов внимания\n",
        "    sentence = clean_sentence(sentence)  # Очистка предложения\n",
        "\n",
        "    # Преобразование предложения в последовательность индексов\n",
        "    inputs = [inp_lang_tokenizer.word_index.get(i, inp_lang_tokenizer.word_index['<unk>']) for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_len_inp, padding='post')  # Дополнение до максимальной длины\n",
        "    inputs = tf.convert_to_tensor(inputs)  # Преобразование в тензор\n",
        "\n",
        "    result = ''  # Инициализация переменной для хранения результата\n",
        "    enc_out, enc_hidden_h, enc_hidden_c = encoder(inputs)  # Кодирование входного предложения\n",
        "    dec_hidden = enc_hidden_h  # Инициализация скрытого состояния декодера\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)  # Начальный вход для декодера (токен <start>)\n",
        "\n",
        "    # Цикл по временным шагам для генерации перевода\n",
        "    for t in range(max_len_targ):\n",
        "        # Декодирование и предсказание следующего слова\n",
        "        predictions, dec_hidden_h, dec_hidden_c, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1,))  # Преобразование весов внимания\n",
        "        attention_plot[t] = attention_weights.numpy()  # Сохранение весов внимания\n",
        "\n",
        "        # Получение индекса предсказанного слова\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        # Добавление предсказанного слова к результату\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        # Если предсказано слово <end>, завершаем генерацию\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, attention_plot\n",
        "\n",
        "        # Обновление входного слова для следующего шага\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, attention_plot  # Возврат результата и весов внимания\n",
        "\n",
        "# Определение максимальных длин входных и целевых последовательностей\n",
        "max_len_inp = input_tensor.shape[1]\n",
        "max_len_targ = target_tensor.shape[1]\n",
        "\n",
        "# Функция для визуализации карты внимания\n",
        "def plot_attention_map(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10, 10))  # Создание фигуры\n",
        "    ax = fig.add_subplot(1, 1, 1)  # Добавление подграфика\n",
        "    # Обрезка карты внимания до длины предсказанного и исходного предложения\n",
        "    attention = attention[:len(predicted_sentence.split(' ')), :len(sentence.split(' '))]\n",
        "    ax.matshow(attention, cmap='viridis')  # Отображение карты внимания\n",
        "\n",
        "    # Настройка меток осей\n",
        "    ax.set_xticklabels([''] + sentence.split(' '), rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence.split(' '))\n",
        "\n",
        "    plt.show()  # Отображение графика\n",
        "\n",
        "# Пример использования\n",
        "sentence = \"how did you become a senior developer?\"\n",
        "result, attention_plot = evaluate_sentence(sentence)  # Генерация перевода\n",
        "print('Перевод:', result)  # Вывод перевода\n",
        "\n",
        "# Визуализация карты внимания\n",
        "import matplotlib.pyplot as plt\n",
        "plot_attention_map(attention_plot, sentence, result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
