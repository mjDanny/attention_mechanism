{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, LSTM, Embedding, Dense\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "v0qQaplFyUdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.yandexcloud.net/academy.ai/LLM/dialogs.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xnm81nCyFe-",
        "outputId": "dcacda42-117c-4ccd-9e63-aa2002a0ea99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-21 11:21:52--  https://storage.yandexcloud.net/academy.ai/LLM/dialogs.txt\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 243904 (238K) [text/plain]\n",
            "Saving to: ‘dialogs.txt’\n",
            "\n",
            "dialogs.txt         100%[===================>] 238.19K   179KB/s    in 1.3s    \n",
            "\n",
            "2024-10-21 11:21:55 (179 KB/s) - ‘dialogs.txt’ saved [243904/243904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionMechanism(Layer):\n",
        "    def __init__(self, method, units):\n",
        "        super(AttentionMechanism, self).__init__()\n",
        "        self.method = method\n",
        "        self.units = units\n",
        "\n",
        "        if self.method == 'bahdanau':\n",
        "            self.W1 = Dense(units)\n",
        "            self.W2 = Dense(units)\n",
        "            self.V = Dense(1)\n",
        "        elif self.method == 'luong_gen':\n",
        "            self.W = Dense(units)\n",
        "        elif self.method == 'luong_concat':\n",
        "            self.W = Dense(units)\n",
        "            self.V = Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        if self.method == 'bahdanau':\n",
        "            query_with_time_axis = tf.expand_dims(query, 1)\n",
        "            score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "        elif self.method == 'luong_gen':\n",
        "            score = tf.matmul(values, tf.expand_dims(query, 2))\n",
        "        elif self.method == 'luong_concat':\n",
        "            query_with_time_axis = tf.expand_dims(query, 1)\n",
        "            score = self.V(tf.nn.tanh(self.W(tf.concat([query_with_time_axis, values], axis=-1))))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "9cwik5HCyGP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = LSTM(self.enc_units, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, state_h, state_c = self.lstm(x)\n",
        "        return output, state_h, state_c\n"
      ],
      "metadata": {
        "id": "V0DgAIYFyKAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDecoder(Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_method='bahdanau'):\n",
        "        super(TextDecoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True)\n",
        "        self.fc = Dense(vocab_size)\n",
        "        self.attention = AttentionMechanism(method=attention_method, units=self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state_h, state_c = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state_h, state_c, attention_weights\n"
      ],
      "metadata": {
        "id": "fAmUuLsTyK7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Zа-яА-Я?.!,¿]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence\n",
        "\n",
        "def load_dialogs(path):\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    with open(path, encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            if len(parts) == 2:\n",
        "                input_texts.append(clean_sentence(parts[0]))\n",
        "                target_texts.append(clean_sentence(parts[1]))\n",
        "    return input_texts, target_texts\n",
        "\n",
        "def tokenize_texts(texts, vocab_size):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, filters='', oov_token='<unk>')\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    tensor = tokenizer.texts_to_sequences(texts)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, tokenizer\n"
      ],
      "metadata": {
        "id": "3BPaBliuyNH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'dialogs.txt'\n",
        "input_texts, target_texts = load_dialogs(path)\n",
        "vocab_size = 5000\n",
        "\n",
        "input_tensor, inp_lang_tokenizer = tokenize_texts(input_texts, vocab_size)\n",
        "target_tensor, targ_lang_tokenizer = tokenize_texts(target_texts, vocab_size)\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "ZWkSYkWfyOYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 256\n",
        "units = 512\n",
        "batch_size = 64\n",
        "\n",
        "encoder = TextEncoder(vocab_size, embedding_dim, units, batch_size)\n",
        "decoder = TextDecoder(vocab_size, embedding_dim, units, batch_size)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def calculate_loss(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden_h, enc_hidden_c = encoder(inp)\n",
        "        dec_hidden = enc_hidden_h\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * batch_size, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden_h, dec_hidden_c, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += calculate_loss(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = loss / int(targ.shape[1])\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    enc_hidden = tf.zeros((batch_size, units))\n",
        "    for batch in range(len(input_tensor_train)//batch_size):\n",
        "        batch_input = input_tensor_train[batch*batch_size:(batch+1)*batch_size]\n",
        "        batch_target = target_tensor_train[batch*batch_size:(batch+1)*batch_size]\n",
        "        batch_loss = train_step(batch_input, batch_target, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(input_tensor_train)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F2gbotiyPko",
        "outputId": "901b9cd0-7652-44ae-9018-69afd1422a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.035757068544626236\n",
            "Epoch 2, Loss: 0.03022547997534275\n",
            "Epoch 3, Loss: 0.02861032448709011\n",
            "Epoch 4, Loss: 0.02724066935479641\n",
            "Epoch 5, Loss: 0.02627233974635601\n",
            "Epoch 6, Loss: 0.025421254336833954\n",
            "Epoch 7, Loss: 0.024679934605956078\n",
            "Epoch 8, Loss: 0.024048564955592155\n",
            "Epoch 9, Loss: 0.0234934464097023\n",
            "Epoch 10, Loss: 0.02299727126955986\n",
            "Epoch 11, Loss: 0.02255803346633911\n",
            "Epoch 12, Loss: 0.02215965837240219\n",
            "Epoch 13, Loss: 0.021751046180725098\n",
            "Epoch 14, Loss: 0.021349593997001648\n",
            "Epoch 15, Loss: 0.020982764661312103\n",
            "Epoch 16, Loss: 0.020624026656150818\n",
            "Epoch 17, Loss: 0.020216185599565506\n",
            "Epoch 18, Loss: 0.01982620730996132\n",
            "Epoch 19, Loss: 0.01945793442428112\n",
            "Epoch 20, Loss: 0.01912458799779415\n",
            "Epoch 21, Loss: 0.01877514272928238\n",
            "Epoch 22, Loss: 0.018467292189598083\n",
            "Epoch 23, Loss: 0.018138965591788292\n",
            "Epoch 24, Loss: 0.017778055742383003\n",
            "Epoch 25, Loss: 0.0174751877784729\n",
            "Epoch 26, Loss: 0.01722044125199318\n",
            "Epoch 27, Loss: 0.016835933551192284\n",
            "Epoch 28, Loss: 0.016413217410445213\n",
            "Epoch 29, Loss: 0.015993798151612282\n",
            "Epoch 30, Loss: 0.015632938593626022\n",
            "Epoch 31, Loss: 0.015347982756793499\n",
            "Epoch 32, Loss: 0.015128661878407001\n",
            "Epoch 33, Loss: 0.014937929809093475\n",
            "Epoch 34, Loss: 0.01458959374576807\n",
            "Epoch 35, Loss: 0.014234175905585289\n",
            "Epoch 36, Loss: 0.013946195133030415\n",
            "Epoch 37, Loss: 0.013603986240923405\n",
            "Epoch 38, Loss: 0.013313481584191322\n",
            "Epoch 39, Loss: 0.013000485487282276\n",
            "Epoch 40, Loss: 0.012672715820372105\n",
            "Epoch 41, Loss: 0.012291887775063515\n",
            "Epoch 42, Loss: 0.011935560032725334\n",
            "Epoch 43, Loss: 0.011514787562191486\n",
            "Epoch 44, Loss: 0.011125181801617146\n",
            "Epoch 45, Loss: 0.010753943584859371\n",
            "Epoch 46, Loss: 0.01041280385106802\n",
            "Epoch 47, Loss: 0.010153957642614841\n",
            "Epoch 48, Loss: 0.009928759187459946\n",
            "Epoch 49, Loss: 0.009733013808727264\n",
            "Epoch 50, Loss: 0.009366841055452824\n",
            "Epoch 51, Loss: 0.008972431533038616\n",
            "Epoch 52, Loss: 0.008535291999578476\n",
            "Epoch 53, Loss: 0.008136318065226078\n",
            "Epoch 54, Loss: 0.007743834983557463\n",
            "Epoch 55, Loss: 0.007357668597251177\n",
            "Epoch 56, Loss: 0.0070427050814032555\n",
            "Epoch 57, Loss: 0.006787137594074011\n",
            "Epoch 58, Loss: 0.006549508310854435\n",
            "Epoch 59, Loss: 0.006242000497877598\n",
            "Epoch 60, Loss: 0.005838003009557724\n",
            "Epoch 61, Loss: 0.005497980397194624\n",
            "Epoch 62, Loss: 0.005231877788901329\n",
            "Epoch 63, Loss: 0.004976151045411825\n",
            "Epoch 64, Loss: 0.004560693632811308\n",
            "Epoch 65, Loss: 0.004197251051664352\n",
            "Epoch 66, Loss: 0.0038898505736142397\n",
            "Epoch 67, Loss: 0.0035777718294411898\n",
            "Epoch 68, Loss: 0.0033121355809271336\n",
            "Epoch 69, Loss: 0.003041647607460618\n",
            "Epoch 70, Loss: 0.0027648922987282276\n",
            "Epoch 71, Loss: 0.0025540865026414394\n",
            "Epoch 72, Loss: 0.002345847897231579\n",
            "Epoch 73, Loss: 0.0021440873388201\n",
            "Epoch 74, Loss: 0.00195687054656446\n",
            "Epoch 75, Loss: 0.001819542609155178\n",
            "Epoch 76, Loss: 0.0017031481256708503\n",
            "Epoch 77, Loss: 0.001583587029017508\n",
            "Epoch 78, Loss: 0.001459820312447846\n",
            "Epoch 79, Loss: 0.0013743165181949735\n",
            "Epoch 80, Loss: 0.001302636694163084\n",
            "Epoch 81, Loss: 0.0012350787874311209\n",
            "Epoch 82, Loss: 0.001167986774817109\n",
            "Epoch 83, Loss: 0.0011123822769150138\n",
            "Epoch 84, Loss: 0.001072448561899364\n",
            "Epoch 85, Loss: 0.0010375060373917222\n",
            "Epoch 86, Loss: 0.0010054070735350251\n",
            "Epoch 87, Loss: 0.0009805795270949602\n",
            "Epoch 88, Loss: 0.0009466413757763803\n",
            "Epoch 89, Loss: 0.0008905419381335378\n",
            "Epoch 90, Loss: 0.0008448885637335479\n",
            "Epoch 91, Loss: 0.0008026076829992235\n",
            "Epoch 92, Loss: 0.0007699855486862361\n",
            "Epoch 93, Loss: 0.0007392304833047092\n",
            "Epoch 94, Loss: 0.0007191509357653558\n",
            "Epoch 95, Loss: 0.0007018072647042572\n",
            "Epoch 96, Loss: 0.0006830423371866345\n",
            "Epoch 97, Loss: 0.0006733633344992995\n",
            "Epoch 98, Loss: 0.0006578136817552149\n",
            "Epoch 99, Loss: 0.0006520277238450944\n",
            "Epoch 100, Loss: 0.0006456344272010028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_sentence(sentence):\n",
        "    attention_plot = np.zeros((max_len_targ, max_len_inp))\n",
        "    sentence = clean_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang_tokenizer.word_index.get(i, inp_lang_tokenizer.word_index['<unk>']) for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_len_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "    enc_out, enc_hidden_h, enc_hidden_c = encoder(inputs)\n",
        "    dec_hidden = enc_hidden_h\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_len_targ):\n",
        "        predictions, dec_hidden_h, dec_hidden_c, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1,))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, attention_plot\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, attention_plot\n",
        "\n",
        "max_len_inp = input_tensor.shape[1]\n",
        "max_len_targ = target_tensor.shape[1]\n",
        "\n",
        "def plot_attention_map(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    attention = attention[:len(predicted_sentence.split(' ')), :len(sentence.split(' '))]\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence.split(' '), rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence.split(' '))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "sentence = \"how did you become a senior developer?\"\n",
        "result, attention_plot = evaluate_sentence(sentence)\n",
        "print('Перевод:', result)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_attention_map(attention_plot, sentence, result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "90Quri2byRWQ",
        "outputId": "86475f16-cccf-4bdc-f249-88093fa6e9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Перевод: i enjoy the kinds of instruments that i enjoy the kinds of instruments that i enjoy the kinds of instruments that i enjoy the \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b10ca10af151>:38: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence.split(' '), rotation=90)\n",
            "<ipython-input-9-b10ca10af151>:39: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence.split(' '))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAANxCAYAAABNJcSBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtoElEQVR4nO3deXiU9b3//9eErEASZN+XICBhkQBaFITIcoQeylYLKhYQ0EqPsogoHI9HUCGoRIVWgUNlVY5YNhe0oEhYAoeyySLIrgk1ChVJkEggzOf7Bz/mR5qwKffMG3k+rmuukjuTvD/B8Ow998x9j8855wQABoSFegEAcA5BAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECEHDw4EG1a9dOdevW1QsvvBD0+QQJQMDDDz+svLw8DRo0SK+99pqGDh0a1Pk+Lj8C4Jy4uDitXbtWDRs2VGZmpu644w5VrVpVdevW1ejRozV16lRlZWVp+vTpnsxnDwlAQFxcnM6cOSNJqlatmtLT03XzzTfr2LFjys/P16FDh3Tw4EHP5rOHBCCgb9++qlmzpsaMGROS+QQJQEBGRoY2btyoHj16hGQ+D9kABFSvXl2/+c1v1L9/f08fml0IQQJQQEREhBYsWBCS2QQJQCHdunXT4sWLgz43POgTAZhXp04dPfvss0pPT1ezZs1UokSJAp8fPHiwJ3M5qA2gkFq1al3wcz6fTwcOHPBkLkECYAbHkABc0KlTp7R7927l5+cHZR5BAlBIbm6uBgwYoOLFi6tBgwbKyMiQJD366KMaP368Z3MJEoBCRo0apa1btyotLU3R0dGB7e3bt9e8efM8m8uzbAAKWbx4sebNm6cWLVrI5/MFtjdo0ED79+/3bC57SAAKOXLkiMqXL19o+4kTJwoE6mojSAAKad68uZYsWRL4+FyE/vKXv+i2227zbC4P2QAUMm7cOHXq1Ek7d+5Ufn6+Jk6cqJ07d2rt2rVauXKlZ3PZQwJQSKtWrfTZZ58pPz9fjRo10rJly1S+fHmtW7dOzZo182wuL4wEYAYP2QAU6cyZM1q0aJF27dolSUpMTFTXrl0VHu5dNthDglmrV6/W1KlTtX//fs2fP19VqlTRnDlzVKtWLbVq1SrUy/tF+/zzz9WlSxd98803qlevniRpz549KleunN5//301bNjQk7kcQ4JJCxYs0F133aWYmBht2bJFeXl5kqTs7GyNGzcuxKv75Rs4cKAaNGigQ4cOafPmzdq8ebMyMzPVuHFjPfTQQ57NZQ8JJiUlJWnYsGHq06ePYmNjtXXrViUkJGjLli3q1KmTvvnmm1Av8RctJiZGGzduVIMGDQps37Fjh2655Rb9+OOPnsxlDwkm7d69W61bty60PT4+XseOHQv+gq4zdevW1bffflto++HDh3XjjTd6NpcgwaSKFStq3759hbavWbNGCQkJIVjR9SUlJUWDBw/W/PnzdejQIR06dEjz58/X0KFD9cILLygnJydwu5p4yAaTUlJS9Oabb2r69Onq0KGDPvzwQ3311VcaNmyYnn76aT366KOhXuIvWljY/7+vcu5V2udScf7HPp8v8D5uVwNP+8OkkSNHyu/3q127dsrNzVXr1q0VFRWlxx9/nBgFwYoVK0Iylz0kmHbq1Cnt27dPP/zwgxITE1WyZMlQLwkeIkgAinTs2DG98cYbgRdGNmjQQP3791d8fLxnMwkSTDp58qT+9Kc/acWKFTp8+LD8fn+Bz2/evDlEK7s+bNy4MfA6sFtvvVWStGHDBv34449atmyZmjZt6slcggSTevfurWXLlunuu+9WhQoVCl2D55lnngnRyq4Pd9xxh2688UZNmzYtcKpIfn6+Bg4cqAMHDmjVqlWezCVIMCk+Pl4ffvihWrZsGeqlBF1+fr7GjRun/v37q2rVqiFZw7lXyN90000Ftu/cuVPNmzdXbm6uJ3N5HRJMqlKlimJjY0O9jJAIDw/XSy+9FLR3+ihKXFxc4ML+58vMzPT0vwtBgkmpqal68skn9dVXX4V6KSHRtm1bTy+Edim9evXSgAEDNG/ePGVmZiozM1Nvv/22Bg4cqHvvvdezubwOCSY1b95cJ0+eVEJCgooXL66IiIgCnz969GiIVhYcnTp10siRI7V9+/Yi38q6S5cuns6fMGGCfD6f+vTpE9hTi4iI0KBBgzx9GySOIcGk9u3bKyMjQwMGDCjyoHbfvn1DtLLgOP+V0v/qar86+mJyc3MD7zJSu3ZtFS9e3NN5BAkmFS9eXOvWrdPNN98c6qUgiHjIBpNuuukmzy5xgaL16NHjsu+7cOFCT9ZAkGDS+PHjNXz4cI0dO1aNGjUqdAwpLi4uRCsLnpUrV2rChAkFLiE7YsQI3XHHHZ7M8/IV2JeLh2ww6dwxlH89duTFGeYWvfnmm3rggQfUo0ePwGux0tPTtWjRIs2cOVP33XdfiFfoDYIEky71lHebNm2CtJLQqF+/vh566CENGzaswPaXX35Z06ZNC+w1eSk/P19paWnav3+/7rvvPsXGxurrr79WXFycZyc5EyTAoKioKH3++eeFrs64b98+NWzYUCdPnvR0/ldffaWOHTsqIyNDeXl52rNnjxISEjRkyBDl5eVpypQpnszlGBLMCsXZ5lZUq1ZNy5cvLxSkTz75RNWqVfN8/pAhQ9S8eXNt3bpVZcqUCWzv3r27HnzwQc/mEiSYVNTZ5i+//LLGjh3r6dnmVgwfPlyDBw/WZ599pttvv13S2WNIM2fO1MSJEz2fv3r1aq1du1aRkZEFttesWVP/+Mc/PJtLkGDSsGHD1KVLlyLPNh86dKhnZ5tbMWjQIFWsWFGpqal65513JJ09rjRv3jx17drV8/l+v7/IJw4OHTrk6blsHEOCSaE62xxn9erVS/Hx8fqf//kfxcbGatu2bSpXrpy6du2q6tWra8aMGZ7M5eRamBSqs81xVmpqqtLT05WYmKiTJ0/qvvvuCzxce+GFFzybyx7SBVSvXl3Jyclq06aNkpOTVbt27VAv6boyePBgLVq0SBMmTChwDGXEiBH67W9/q1dffTW0C/RA6dKltWfPHpUtW1Y33HBDoddgnS8YJxfn5+fr7bff1rZt2/TDDz+oadOm6t27t2JiYjybSZAu4M0339SqVauUlpamffv2qUqVKmrTpk0gUHXq1An1En/RTp06pREjRmjKlClFnm0eFRUV4hVefbNmzdI999yjqKgozZo166L39frk4pMnTyo6OtrTGUUhSJchKytLK1eu1AcffKB58+Zd8IDfL8WlDhgX9Y6yXgn22eY4Ky4uTt27d9f999+vdu3aXfTqA1cTQbqI3NxcrVmzRmlpaVqxYoW2bNmi+vXrKzk5Wa+88kqol+eZon75zn/4EIwYZ2dn68yZMypdunSB7UePHlV4ePh1cS6b3+/Xvn37inyTA6//T2HRokWaO3eulixZovj4ePXq1Uv333+/mjdv7ulcORTptttuc9HR0S4pKckNGzbMLV682B09ejTUywqKY8eOFbgdOXLELVu2zP3qV79yn3zySVDW0LFjR/faa68V2j558mTXqVOnoKwhlNatW+dq1arlwsLCnM/nK3ALCwsL2jpycnLc9OnTXYcOHVyxYsVcnTp13JgxYzybxx7SBZQuXVphYWH6t3/7NyUnJys5OVl169YN9bJCauXKlXrssce0adMmz2eVLl1a6enpql+/foHtX3zxhVq2bKnvvvvO8zWEUpMmTVS3bl2NGTNGlSpVKnSAOxSvVt+5c6d69+6tbdu2ebaXzAsjL+C7777T9u3blZaWpqVLl+qpp55SZGSk2rRpozvvvNOTl8+/9957l31fry9hWpQKFSpo9+7dQZmVl5dX5EXuT58+fV1cJ2nv3r2aP39+oVNHgu3kyZN67733NHfuXP3tb39ThQoVNGLECM/msYd0GZxz2rRpk/785z/rrbfe8uyg9r8eu/H5fDr/P0+wjuNs27atwMfOOWVlZWn8+PHKz8/XmjVrPJt9zp133qmGDRvqT3/6U4Ht//Ef/6Ft27Zp9erVnq8hlNq2basnnnhCHTt2DMn8pUuXau7cuVq8eLHCw8N19913q3fv3p4fu2IP6QI2b96stLQ0paWlac2aNTp+/LgaNWqkRx991LNLX5x/4PKTTz7Rk08+qXHjxum2226TJK1bt07/9V//pXHjxnky/5wmTZoUiqEktWjRQtOnT/d09jnPP/+82rdvr61bt6pdu3aSpOXLl2vDhg1atmxZUNYQSo8++qiGDx+ub775psgL1DVu3NjT+d27d1fnzp01e/Zs/frXvy403yvsIV1AeHi4kpKSAq89at26dVAftzds2FBTpkxRq1atCmxfvXq1HnroIU+vh/Ovbz0UFhamcuXKBf11KZ999plefPFFbd26VTExMWrcuLFGjRp1XbwG7ELPdLogXaDu+PHjIXlFPEG6gJycnJA+tRwTE6MNGzaoYcOGBbZv27ZNv/rVr66L4yjXs0u9H12NGjU8X8P+/fs1Y8YM7d+/XxMnTlT58uX10UcfqXr16mrQoIEnMwnSJWzatKnANY2DddmL1q1bKzo6WnPmzFGFChUkSd9++6369OmjkydPev4mgsG+nnNRzv2DOHDggF599dWg/IPAWStXrlSnTp3UsmVLrVq1Srt27VJCQoLGjx+vjRs3av78+d4M9uwFBde4b7/91iUnJzufz+duuOEGd8MNNzifz+fatm3rDh8+7Pn8vXv3uoYNG7rIyEhXu3ZtV7t2bRcZGekaNGjg9u7d6+nsOXPmuPDwcNezZ083ceJEN3HiRNezZ08XERHh3nrrLU9nn5OWluZiYmJc+/btXWRkpNu/f79zzrmUlBT329/+NihrCLXZs2e722+/3VWqVMl9+eWXzjnnXnnlFbd48WLPZ7do0cKlpqY655wrWbJk4O9//fr1rkqVKp7NJUgX0LNnT9e8eXO3c+fOwLbPP//cNW/e3N1zzz1BWYPf73dLly4NRGHZsmXO7/d7Pvemm25yL7/8cqHtqamp7qabbvJ8vnOh+wdhxeuvv+7Kli3rnn/+eRcTExP4+WfMmOGSk5M9n1+iRAl34MAB51zBv/+DBw+6qKgoz+YSpAuIi4tzf//73wttX79+vYuPjw/+goIoMjKyyL2wvXv3evrLeL5Q/YOwon79+m7RokXOuYI///bt212ZMmU8n1+lShWXnp5eaP7ChQtdQkKCZ3N52v8C/H5/kU91RkREFDqv6GqZNGmSHnroIUVHR2vSpEkXve/gwYM9WYMU+us5S1KpUqWUlZWlWrVqFdi+ZcsWValSJShrCKWDBw8qKSmp0PaoqCidOHHC8/n33HOPnnzySf31r3+Vz+eT3+9Xenq6Hn/8cfXp08e7wZ6l7hrXpUsX17p1a/ePf/wjsO3QoUOuTZs2rlu3bp7MrFmzpvvnP/8Z+POFbrVq1fJk/jmvv/66i4yMdA8//LCbPXu2mz17tvvDH/7goqKi3JQpUzydfc7w4cNdq1atXFZWlouNjXV79+51a9ascQkJCW706NFBWUMo1a9fP3Cs6Pw9lEmTJrmkpCTP5+fl5bmBAwe68PBw5/P5XEREhPP5fO7+++93+fn5ns0lSBeQkZHhmjRp4iIiIlxCQoJLSEhw4eHhLikpyWVmZoZ6eZ5buHCha9mypStdurQrXbq0a9myZVAOpp4Tqn8QVkybNs1VqVLFvf32265EiRLuf//3f93zzz8f+HOwZGRkuCVLlrh58+a5PXv2eD6Pp/0vwjmn5cuXB576rl+/vtq3b+/ZvMcee+yy7ufz+ZSamurZOvr27asBAwYE9bpHF5KZmant27frxIkTSkpKCvq5XTt37lRGRoZOnTpVYHswziV86623NHr06MD1oKpUqaLRo0drwIABnsy73N8/6ew7wHiBY0gX8emnn+rTTz8NXI9my5Ytmjt3riR5cgrFli1bCny8efNm5efnq169epKkPXv2qFixYmrWrNlVn32+7OxstW/fXjVq1NADDzygfv36qXLlyp7OLMobb7yhV155RXv37pUk1alTR0OHDtXAgQM9n33gwAF1795d27dvL3AazbnzCb1+pfSPP/6o7t27q3fv3srNzdWOHTuUnp6uqlWrejbTxO+f5/tg16jRo0e7sLAwd+utt7quXbu6bt26Fbh5LTU11f3mN78pcA2mo0ePuq5du7oJEyZ4Pv/w4cMuNTXVNW7c2IWHh7uOHTu6d955x506dcrz2c459/TTT7sSJUq4kSNHunfffde9++67buTIka5kyZLu6aef9nx+586dXdeuXd2RI0dcyZIl3c6dO93q1avdrbfe6latWuX5/A4dOrjJkyc755z7/vvvXYUKFVzVqlVddHS0e/311z2fH6rfP4J0ARUrVnSzZ88O2fzKlSu7HTt2FNq+fft2V6lSpaCuZdOmTe6RRx5x0dHRrmzZsm7o0KGeH08oW7asmzt3bqHtc+fODcrT3mXKlHFbt251zp19CcgXX3zhnHNu+fLlrkmTJkGZf+6//7Rp01zjxo3dmTNn3DvvvBOU14KF6vePt0G6gFOnTgXe7SIUcnJydOTIkULbjxw5ouPHjwdtHVlZWfr444/18ccfq1ixYvr1r3+t7du3KzEx0dPL+J4+fbrIy6U2a9asyOskXW1nzpwJnFxatmxZff3115LOnkMWjGtC5ebmBuYvW7ZMPXr0UFhYmFq0aHHJ89yuhpD9/nmWumvcE0884Z599tmQzf/973/vatas6RYsWOAyMzNdZmammz9/vqtVq5br06ePp7NPnTrl5s+f7/793//dRUREuGbNmrnJkye77OzswH0WLlzoSpUq5dkaHnnkETds2LBC24cPH+7++Mc/ejb3nFatWgVemHjvvfe6jh07ujVr1rg+ffq4Bg0aeD6/UaNGbuLEiS4jI8PFxcW5tWvXOuec27hxo6tQoYLn80P1+8ezbOc5/1kGv9+vWbNmqXHjxmrcuHGhF0l69SzDObm5uXr88cc1ffp0nT59WtLZS6IMGDBAL730kkqUKOHZ7LJly8rv9+vee+/Vgw8+qCZNmhS6z7Fjx5SUlKSDBw9etbnn//3n5+dr5syZql69ulq0aCFJWr9+vTIyMtSnT59CF2672pYuXaoTJ06oR48e2rdvnzp37qw9e/aoTJkymjdvntq2bevp/Pnz5+u+++7TmTNn1K5du8A1oFJSUrRq1Sp99NFHns4P1e8fQTrPnXfeeVn38/l8+vTTTz1ezVknTpwo8DZAXobonDlz5uh3v/td0K9/ZPHv/3xHjx695Bs4Xk3ffPONsrKydPPNNweuj/T3v/9dcXFxhd5i3CvB/v0jSADM4KA2ADMIEgAzCNJlyMvL0+jRo5WXl8d85jPfQxxDugw5OTmKj49XdnZ2SK6zzXzmXy/z2UMCYAZBAmDGdXG2v9/v19dff63Y2Nif9BqSnJycAv8bbMxn/rU83zmn48ePq3LlykW+39z5rotjSIcOHQrapVcBFC0zM/OSl0+5LvaQzp2k2Er/rnBfcN4SuJBQdz9Iry62qsP6Y6Fegj4clRzS+R9Mnh2SuTk/+FWj6ZeX9U6410WQzj1MC/dFhC5IIkihFF0y9L/q4eHBPRXnX8XFhvaQ8eUcLuGgNgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAM67JICUnJ2vo0KGhXgaAqyz0L1/9CRYuXFjoXUAAXPuuySCVLl061EsA4AEesgEw45rcQ7qUvLy8Atf/DdV1ZABcmWtyD+lSUlJSFB8fH7hxLSTg2vCLDNKoUaOUnZ0duGVmZoZ6SQAuwy/yIVtUVJSioqJCvQwAV+gXuYcE4NpEkACYQZAAmHFNHkNKS0sL9RIAeIA9JABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZhAkAGYQJABmECQAZgQ9SDNnzlSpUqWCPRbANSDoQerVq5f27NkT7LEArgHhwR4YExOjmJiYYI8FcA244j0kv9+vlJQU1apVSzExMbr55ps1f/58SVJaWpp8Pp+WL1+u5s2bq3jx4rr99tu1e/fuwNcX9ZBt8uTJql27tiIjI1WvXj3NmTMn8Ln+/furc+fOBe5/+vRplS9fXm+88caVLh+AYVccpJSUFM2ePVtTpkzR559/rmHDhun+++/XypUrA/d56qmnlJqaqo0bNyo8PFz9+/e/4PdbtGiRhgwZouHDh2vHjh36wx/+oAceeEArVqyQJA0cOFB/+9vflJWVFfiaDz74QLm5uerVq1eR3zMvL085OTkFbgDsu6Ig5eXlady4cZo+fbruuusuJSQkqF+/frr//vs1derUwP3Gjh2rNm3aKDExUSNHjtTatWt18uTJIr/nhAkT1K9fP/3xj39U3bp19dhjj6lHjx6aMGGCJOn2228vtNc0Y8YM/e53v1PJkiWL/J4pKSmKj48P3KpVq3YlPyaAELmiIO3bt0+5ubnq0KGDSpYsGbjNnj1b+/fvD9yvcePGgT9XqlRJknT48OEiv+euXbvUsmXLAttatmypXbt2BT4eOHCgZsyYIUn69ttv9dFHH110r2vUqFHKzs4O3DIzM6/kxwQQIld0UPuHH36QJC1ZskRVqlQp8LmoqKhAlCIiIgLbfT6fpLPHnn6qPn36aOTIkVq3bp3Wrl2rWrVq6Y477rjg/aOiohQVFfWT5wEIjSsKUmJioqKiopSRkaE2bdoU+vz5e0mXq379+kpPT1ffvn0D29LT05WYmBj4uEyZMurWrZtmzJihdevW6YEHHrjiOQDsu6IgxcbG6vHHH9ewYcPk9/vVqlUrZWdnKz09XXFxcapRo8YVL2DEiBHq2bOnkpKS1L59e73//vtauHChPvnkkwL3GzhwoDp37qwzZ84UiBeAX44rfh3Sc889p3LlyiklJUUHDhxQqVKl1LRpU/3nf/7nT3pY1q1bN02cOFETJkzQkCFDVKtWLc2YMUPJyckF7te+fXtVqlRJDRo0UOXKla94DgD7rjhIPp9PQ4YM0ZAhQ4r8vHOuwMdNmjQpsC0vL6/Qs2ODBg3SoEGDLjr3xIkT+v777zVgwIArXTKAa0RQX6mdmZmpDz/8UA0aNLjsr/H7/frnP/+p1NRUlSpVSl26dPFwhQBCKahBatq0qapUqaKZM2de9tdkZGSoVq1aqlq1qmbOnKnw8KCf7QIgSIL6r/vIkSNX/DU1a9Ys9DAQwC8T10MCYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYAZBAmAGQQJgBkECYEZIg5SWliafz6djx46FchkAjAhqkJKTkzV06NBgjgRwDeEhGwAzghakfv36aeXKlZo4caJ8Pp98Pp++/PJLSdKmTZvUvHlzFS9eXLfffrt2795d4GvfffddNW3aVNHR0UpISNCYMWOUn58frKUDCJKgBWnixIm67bbb9OCDDyorK0tZWVmqVq2aJOmpp55SamqqNm7cqPDwcPXv3z/wdatXr1afPn00ZMgQ7dy5U1OnTtXMmTM1duzYC87Ky8tTTk5OgRsA+4IWpPj4eEVGRqp48eKqWLGiKlasqGLFikmSxo4dqzZt2igxMVEjR47U2rVrdfLkSUnSmDFjNHLkSPXt21cJCQnq0KGDnnvuOU2dOvWCs1JSUhQfHx+4nQsfANtMHENq3Lhx4M+VKlWSJB0+fFiStHXrVj377LMqWbJk4HZuLys3N7fI7zdq1ChlZ2cHbpmZmd7/EAB+tvBQL0CSIiIiAn/2+XySJL/fL0n64YcfNGbMGPXo0aPQ10VHRxf5/aKiohQVFeXBSgF4KahBioyM1JkzZ67oa5o2bardu3frxhtv9GhVAKwIapBq1qyp9evX68svv1TJkiUDe0EX89///d/q3LmzqlevrrvvvlthYWHaunWrduzYoeeffz4IqwYQLEE9hvT444+rWLFiSkxMVLly5ZSRkXHJr7nrrrv0wQcfaNmyZbrlllvUokULvfLKK6pRo0YQVgwgmHzOORfqRXgtJydH8fHxSvZ1U7gv4tJf4IVQ/zX/f8fmrleddnwf6iXovWHtQzr/05l/CcncnON+3VD3gLKzsxUXF3fR+5p4lg0AJIIEwBCCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTAjJ8UpOTkZA0dOrTIz/Xr10/dunX7GUs6y+fzafHixT/7+wC4doRf7W84ceJEOeeu9rcFcB246kGKj4+/2t8SwHXiqhxDWrJkieLj4/XWW28VesiWnJyswYMH64knnlDp0qVVsWJFjR49usDX7927V61bt1Z0dLQSExP18ccfF/j8qVOn9Mgjj6hSpUqKjo5WjRo1lJKScjWWDsCQn72HNHfuXD388MOaO3euOnfuXCgmkjRr1iw99thjWr9+vdatW6d+/fqpZcuW6tChg/x+v3r06KEKFSpo/fr1ys7OLnR8atKkSXrvvff0zjvvqHr16srMzFRmZuYF15SXl6e8vLzAxzk5OT/3xwQQBD8rSK+99pqeeuopvf/++2rTps0F79e4cWM988wzkqQ6deroz3/+s5YvX64OHTrok08+0RdffKGlS5eqcuXKkqRx48apU6dOga/PyMhQnTp11KpVK/l8PtWoUeOi60pJSdGYMWN+zo8GIAR+8kO2+fPna9iwYfr4448vGiPpbJDOV6lSJR0+fFiStGvXLlWrVi0QI0m67bbbCty/X79++uyzz1SvXj0NHjxYy5Ytu+i8UaNGKTs7O3C72N4UADt+cpCSkpJUrlw5TZ8+/ZLPqkVERBT42Ofzye/3X/aspk2b6uDBg3ruuef0448/qmfPnrr77rsveP+oqCjFxcUVuAGw7ycHqXbt2lqxYoXeffddPfrooz95AfXr11dmZqaysrIC2/7v//6v0P3i4uLUq1cvTZs2TfPmzdOCBQt09OjRnzwXgD0/6xhS3bp1tWLFCiUnJys8PFyvvvrqFX+P9u3bq27duurbt69eeukl5eTk6Kmnnipwn5dfflmVKlVSUlKSwsLC9Ne//lUVK1ZUqVKlfs7yARjzs59lq1evnj799FMlJyerWLFiV/z1YWFhWrRokQYMGKBbb71VNWvW1KRJk9SxY8fAfWJjY/Xiiy9q7969KlasmG655RZ9+OGHCgvjzBfgl8TnroOXVefk5Cg+Pl7Jvm4K90Vc+gu8EOq/Zp8vtPNDrNOO70O9BL03rH1I53868y8hmZtz3K8b6h5Qdnb2JY/nsosBwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMAMggTADIIEwAyCBMCMay5I6enpatSokSIiItStW7dQLwfAVRQe6gVcqccee0xNmjTRRx99pJIlS4Z6OQCuomtuD2n//v1q27atqlatqlKlSoV6OQCuInNBysvL0+DBg1W+fHlFR0erVatW2rBhg7788kv5fD5999136t+/v3w+n2bOnBnq5QK4iswF6YknntCCBQs0a9Ysbd68WTfeeKPuuusuxcbGKisrS3FxcXr11VeVlZWlXr16Ffk98vLylJOTU+AGwD5TQTpx4oQmT56sl156SZ06dVJiYqKmTZummJgYTZ8+XRUrVpTP51N8fLwqVqyomJiYIr9PSkqK4uPjA7dq1aoF+ScB8FOYCtL+/ft1+vRptWzZMrAtIiJCt956q3bt2nXZ32fUqFHKzs4O3DIzM71YLoCr7Jp7lu1yREVFKSoqKtTLAHCFTO0h1a5dW5GRkUpPTw9sO336tDZs2KDExMQQrgxAMJjaQypRooQGDRqkESNGqHTp0qpevbpefPFF5ebmasCAAaFeHgCPmQqSJI0fP15+v1+///3vdfz4cTVv3lxLly7VDTfcEOqlAfCYuSBFR0dr0qRJmjRpUpGfP3bsWHAXBCBoTB1DAnB9I0gAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADMIEgAzAgP9QKCwTknScp3p0O5iNDNliT5Qjw/tE7+kB/qJSg//2RI5+cc94dm7g9n57rL+Dfgc5dzr2vcoUOHVK1atVAvA7iuZWZmqmrVqhe9z3URJL/fr6+//lqxsbHy+a58TyEnJ0fVqlVTZmam4uLiPFgh85n/y53vnNPx48dVuXJlhYVd/CjRdfGQLSws7JJlvhxxcXEh+YVgPvOv9fnx8fGXdT8OagMwgyABMIMgXYaoqCg988wzioqKYj7zme+h6+KgNoBrA3tIAMwgSADMIEgAzCBIAMwgSADMIEgAzCBIAMwgSADM+H934p/v3z/lJQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}